{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34269e93",
   "metadata": {},
   "source": [
    "## Link For The File (Kaggle):\n",
    "\n",
    "https://www.kaggle.com/code/rameshbabuash/unsloth2-uncompiled-kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567772f",
   "metadata": {
    "papermill": {
     "duration": 0.002681,
     "end_time": "2025-03-05T15:02:36.934708",
     "exception": false,
     "start_time": "2025-03-05T15:02:36.932027",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Install Dependencies\n",
    "Installs core libraries needed for training, tokenization, and data handling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5548f7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:02:36.940265Z",
     "iopub.status.busy": "2025-03-05T15:02:36.939989Z",
     "iopub.status.idle": "2025-03-05T15:03:26.059370Z",
     "shell.execute_reply": "2025-03-05T15:03:26.058133Z"
    },
    "papermill": {
     "duration": 49.123931,
     "end_time": "2025-03-05T15:03:26.061139",
     "exception": false,
     "start_time": "2025-03-05T15:02:36.937208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install --no-deps bitsandbytes==0.45.3 accelerate==1.4.0 peft==0.14.0 triton==3.2.0 trl==0.15.2\n",
    "!pip install sentencepiece==0.2.0 protobuf==5.29.3 datasets==3.3.2 huggingface-hub==0.29.1 hf_transfer==0.1.9\n",
    "!pip install rich==13.9.4 psutil==7.0.0 safetensors==0.5.3\n",
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e53427",
   "metadata": {
    "papermill": {
     "duration": 0.002245,
     "end_time": "2025-03-05T15:03:26.066042",
     "exception": false,
     "start_time": "2025-03-05T15:03:26.063797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# GPU Info\n",
    "Prints the number of GPUs and their names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85941b63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:03:26.071400Z",
     "iopub.status.busy": "2025-03-05T15:03:26.071134Z",
     "iopub.status.idle": "2025-03-05T15:03:29.378371Z",
     "shell.execute_reply": "2025-03-05T15:03:29.377345Z"
    },
    "papermill": {
     "duration": 3.311495,
     "end_time": "2025-03-05T15:03:29.379704",
     "exception": false,
     "start_time": "2025-03-05T15:03:26.068209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 2\n",
      "GPU 0: Tesla T4\n",
      "GPU 1: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# This prints the number of GPUs available\n",
    "num_gpus = torch.cuda.device_count()\n",
    "print(\"Number of GPUs available:\", num_gpus)\n",
    "\n",
    "# Print the name of each GPU\n",
    "for i in range(num_gpus):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412531a",
   "metadata": {
    "papermill": {
     "duration": 0.002049,
     "end_time": "2025-03-05T15:03:29.384254",
     "exception": false,
     "start_time": "2025-03-05T15:03:29.382205",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Distributed Training Script: unsloth.py\n",
    "\n",
    "This script sets up distributed training using Accelerate and FSDP2. It:\n",
    "- Sets up environment variables.\n",
    "- Initializes and cleans up the distributed process group.\n",
    "- Loads a quantized model (Meta-Llama-3.1-8B) and applies LoRA.\n",
    "- Loads a dataset and trains using SFTTrainer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6208d380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:03:29.389632Z",
     "iopub.status.busy": "2025-03-05T15:03:29.389292Z",
     "iopub.status.idle": "2025-03-05T15:03:29.394820Z",
     "shell.execute_reply": "2025-03-05T15:03:29.394154Z"
    },
    "papermill": {
     "duration": 0.009474,
     "end_time": "2025-03-05T15:03:29.395870",
     "exception": false,
     "start_time": "2025-03-05T15:03:29.386396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/unsloth.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/unsloth.py\n",
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, set_seed\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from accelerate import Accelerator\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Environment Variables\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "# Remove unsupported expandable_segments option to avoid warnings.\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"roundup_power2_divisions:[32:256,64:128,256:64,>:32]\"\n",
    "# Optionally suppress XLA warnings.\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "def setup_distributed():\n",
    "    if torch.distributed.is_available() and not torch.distributed.is_initialized():\n",
    "        torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    if torch.distributed.is_initialized():\n",
    "        local_rank = int(os.environ.get(\"LOCAL_RANK\", \"0\"))\n",
    "        # Use a list for device_ids as required.\n",
    "        torch.distributed.barrier(device_ids=[local_rank])\n",
    "\n",
    "def cleanup_distributed():\n",
    "    if torch.distributed.is_initialized():\n",
    "        torch.distributed.destroy_process_group()\n",
    "\n",
    "def main():\n",
    "    # Setup distributed training environment.\n",
    "    setup_distributed()\n",
    "\n",
    "    # Set the seed for reproducibility.\n",
    "    set_seed(42)\n",
    "    \n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\"\n",
    "\n",
    "    # Set default data type and define quantization configuration.\n",
    "    torch.set_default_dtype(torch.float16)\n",
    "    dtype = torch.float16\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit              = True,\n",
    "        bnb_4bit_use_double_quant = True,\n",
    "        bnb_4bit_quant_type       = \"nf4\",\n",
    "        bnb_4bit_compute_dtype    = dtype,\n",
    "        bnb_4bit_quant_storage    = torch.float16\n",
    "    )\n",
    "\n",
    "    # Initialize Accelerator for device mapping.\n",
    "    accelerator = Accelerator()\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        attn_implementation = \"sdpa\",\n",
    "        quantization_config = bnb_config,\n",
    "        device_map={\"\": accelerator.process_index}\n",
    "    )\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    # Configure LoRA for parameter-efficient fine-tuning.\n",
    "    lora_config = LoraConfig(\n",
    "        r = 64,\n",
    "        lora_alpha = 128,\n",
    "        target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                          \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "        lora_dropout = 0,\n",
    "        bias = \"none\",\n",
    "        task_type = TaskType.CAUSAL_LM,\n",
    "    )\n",
    "\n",
    "    # Apply LoRA to the model and freeze non-LoRA parameters.\n",
    "    model = get_peft_model(model, lora_config)\n",
    "    with torch.no_grad():\n",
    "        for name, param in model.named_parameters():\n",
    "            if \".lora_A.\" in name or \".lora_B.\" in name:\n",
    "                param.requires_grad_(True)\n",
    "            else:\n",
    "                param.requires_grad_(False)\n",
    "\n",
    "    model.config.use_cache = False\n",
    "                \n",
    "    model.gradient_checkpointing_enable()\n",
    "    model.enable_input_require_grads()\n",
    "    \n",
    "    # Get dataset\n",
    "    url = \"https://huggingface.co/datasets/laion/OIG/resolve/main/unified_chip2.jsonl\"\n",
    "    dataset = load_dataset(\"json\", data_files={\"train\": url}, split=\"train[:10%]\")\n",
    "\n",
    "    # Create the SFTTrainer for training the model.\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset,\n",
    "        processing_class=tokenizer,\n",
    "        args=SFTConfig(\n",
    "            per_device_train_batch_size=2,\n",
    "            gradient_accumulation_steps=4,\n",
    "            warmup_steps=1,\n",
    "            max_steps=100,\n",
    "            logging_steps=1,\n",
    "            output_dir=\"outputs\",\n",
    "            seed=3407,\n",
    "            max_seq_length=2048,\n",
    "            fp16=model.get_input_embeddings().weight.dtype == torch.float16,\n",
    "            bf16=model.get_input_embeddings().weight.dtype == torch.bfloat16,\n",
    "            report_to=\"none\",  # For W&B\n",
    "            dataset_num_proc=4,\n",
    "            gradient_checkpointing=True,\n",
    "            gradient_checkpointing_kwargs={\"use_reentrant\": True},\n",
    "            label_names = [\"input_ids\", \"labels\", \"attention_mask\"]\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    accelerator.print(f\"Model Summary:\\n{trainer.model}\")\n",
    "    \n",
    "    # Optionally print trainable parameters if the method is available.\n",
    "    if hasattr(trainer.model, \"print_trainable_parameters\"):\n",
    "        trainer.model.print_trainable_parameters()\n",
    "    \n",
    "    # Begin training.\n",
    "    trainer.train()\n",
    "    \n",
    "    # Clean up distributed resources.\n",
    "    cleanup_distributed()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d881c",
   "metadata": {
    "papermill": {
     "duration": 0.002017,
     "end_time": "2025-03-05T15:03:29.400184",
     "exception": false,
     "start_time": "2025-03-05T15:03:29.398167",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Accelerate Configuration (config.yaml)\n",
    "\n",
    "This configuration file sets up distributed training using FSDPv2 with the following key settings:\n",
    "- **compute_environment:** Running on a local machine.\n",
    "- **distributed_type:** Using Fully Sharded Data Parallel (FSDP2) for efficient distributed training.\n",
    "- **fsdp_config:** Detailed options for FSDP2, such as wrapping policy, prefetching, parameter offloading, and sharding strategy.\n",
    "- **machine_rank, num_processes:** Define the rank and the number of processes (GPUs) per machine.\n",
    "- **TPU and CPU Settings:** TPU options are disabled, and the training will run on GPUs.\n",
    "\n",
    "Each setting is annotated with inline comments in the YAML file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "134a5aaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:03:29.405255Z",
     "iopub.status.busy": "2025-03-05T15:03:29.405020Z",
     "iopub.status.idle": "2025-03-05T15:03:29.409682Z",
     "shell.execute_reply": "2025-03-05T15:03:29.408934Z"
    },
    "papermill": {
     "duration": 0.008431,
     "end_time": "2025-03-05T15:03:29.410775",
     "exception": false,
     "start_time": "2025-03-05T15:03:29.402344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /kaggle/working/config.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile /kaggle/working/config.yaml\n",
    "compute_environment: LOCAL_MACHINE  # Running on a local machine\n",
    "debug: false                        # Debug mode disabled\n",
    "distributed_type: FSDP              # Use Fully Sharded Data Parallel for distributed training version 2\n",
    "downcast_bf16: 'no'                 # Do not downcast BF16 precision\n",
    "fsdp_config:                        # FSDP-specific configuration\n",
    "  fsdp_auto_wrap_policy: TRANSFORMER_BASED_WRAP  # Automatically wrap transformer modules for FSDP\n",
    "  fsdp_backward_prefetch: BACKWARD_PRE             # Enable backward prefetching to optimize memory usage\n",
    "  fsdp_cpu_ram_efficient_loading: true            # Enable efficient CPU RAM loading during FSDP initialization\n",
    "  fsdp_forward_prefetch: false                     # Disable forward prefetching\n",
    "  fsdp_offload_params: true                        # Offload parameters to CPU when not in use\n",
    "  fsdp_sharding_strategy: FULL_SHARD               # Use full sharding strategy for optimal memory usage\n",
    "  fsdp_state_dict_type: SHARDED_STATE_DICT         # Save state dict in a sharded format\n",
    "  fsdp_sync_module_states: true                    # Synchronize module states across processes\n",
    "  fsdp_use_orig_params: false                      # Do not use original parameters\n",
    "machine_rank: 0                      # Rank of this machine in multi-machine setups\n",
    "main_training_function: main         # Name of the main training function to execute\n",
    "mixed_precision: 'no'                # Mixed precision training -- choose whatever you want\n",
    "num_machines: 1                      # Total number of machines involved in training\n",
    "num_processes: 2                     # Number of processes (GPUs) per machine\n",
    "rdzv_backend: static                 # Use a static backend for rendezvous (process group setup)\n",
    "same_network: true                   # All machines are on the same network\n",
    "tpu_env: []                          # TPU environment settings (empty indicates TPU not used)\n",
    "tpu_use_cluster: false               # Do not use a TPU cluster\n",
    "tpu_use_sudo: false                  # TPU sudo access is not required\n",
    "use_cpu: false                       # Training will run on GPUs, not on CPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644f503",
   "metadata": {
    "papermill": {
     "duration": 0.002218,
     "end_time": "2025-03-05T15:03:29.415294",
     "exception": false,
     "start_time": "2025-03-05T15:03:29.413076",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Launching Distributed Training with Accelerate\n",
    "\n",
    "This cell uses the `accelerate` launcher to start the training script (`unsloth.py`) using the configuration specified in `config.yaml`.  \n",
    "- The configuration file sets up distributed training with FSDP2 and GPU settings.\n",
    "- The script is executed across the processes defined in the config.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe84bc83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T15:03:29.420492Z",
     "iopub.status.busy": "2025-03-05T15:03:29.420293Z",
     "iopub.status.idle": "2025-03-05T15:32:33.205679Z",
     "shell.execute_reply": "2025-03-05T15:32:33.204674Z"
    },
    "papermill": {
     "duration": 1743.790189,
     "end_time": "2025-03-05T15:32:33.207734",
     "exception": false,
     "start_time": "2025-03-05T15:03:29.417545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-05 15:03:47.034655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-03-05 15:03:47.034646: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-03-05 15:03:47.233961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-03-05 15:03:47.233967: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-03-05 15:03:47.292500: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "2025-03-05 15:03:47.292504: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "config.json: 100%|█████████████████████████████| 947/947 [00:00<00:00, 7.02MB/s]\r\n",
      "model.safetensors.index.json: 100%|████████| 23.9k/23.9k [00:00<00:00, 19.0MB/s]\r\n",
      "Downloading shards:   0%|                                 | 0/4 [00:00<?, ?it/s]\r\n",
      "model-00001-of-00004.safetensors:   0%|             | 0.00/4.98G [00:00<?, ?B/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   0%|     | 10.5M/4.98G [00:00<00:48, 101MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   1%|     | 31.5M/4.98G [00:00<00:30, 161MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   1%|     | 62.9M/4.98G [00:00<00:23, 213MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   2%|     | 94.4M/4.98G [00:00<00:20, 233MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   3%|▏     | 126M/4.98G [00:00<00:20, 242MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   3%|▏     | 157M/4.98G [00:00<00:19, 247MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   4%|▏     | 189M/4.98G [00:00<00:19, 249MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   4%|▎     | 220M/4.98G [00:00<00:21, 220MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   5%|▎     | 252M/4.98G [00:01<00:20, 229MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   6%|▎     | 283M/4.98G [00:01<00:20, 234MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   6%|▍     | 315M/4.98G [00:01<00:19, 239MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   7%|▍     | 346M/4.98G [00:01<00:19, 241MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   8%|▍     | 377M/4.98G [00:01<00:18, 243MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   8%|▍     | 409M/4.98G [00:01<00:18, 246MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 440M/4.98G [00:02<00:25, 181MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:   9%|▌     | 472M/4.98G [00:02<00:22, 198MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  10%|▌     | 503M/4.98G [00:02<00:21, 210MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 535M/4.98G [00:02<00:20, 220MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  11%|▋     | 566M/4.98G [00:02<00:19, 227MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  12%|▋     | 598M/4.98G [00:02<00:18, 233MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 629M/4.98G [00:02<00:24, 176MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  13%|▊     | 661M/4.98G [00:03<00:22, 192MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  14%|▊     | 692M/4.98G [00:03<00:20, 208MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  15%|▊     | 724M/4.98G [00:03<00:19, 217MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  15%|▉     | 755M/4.98G [00:03<00:18, 225MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  16%|▉     | 786M/4.98G [00:03<00:18, 231MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  16%|▉     | 818M/4.98G [00:03<00:17, 238MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  17%|█     | 849M/4.98G [00:03<00:23, 177MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  18%|█     | 881M/4.98G [00:04<00:21, 194MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  18%|█     | 912M/4.98G [00:04<00:19, 208MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  19%|█▏    | 944M/4.98G [00:04<00:18, 220MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  20%|█▏    | 975M/4.98G [00:04<00:17, 229MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  20%|█    | 1.01G/4.98G [00:04<00:16, 234MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  21%|█    | 1.04G/4.98G [00:04<00:16, 239MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  21%|█    | 1.07G/4.98G [00:05<00:22, 176MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  22%|█    | 1.10G/4.98G [00:05<00:20, 194MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  23%|█▏   | 1.13G/4.98G [00:05<00:18, 207MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  23%|█▏   | 1.16G/4.98G [00:05<00:17, 218MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  24%|█▏   | 1.20G/4.98G [00:05<00:16, 228MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  25%|█▏   | 1.23G/4.98G [00:05<00:16, 232MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  25%|█▎   | 1.26G/4.98G [00:05<00:21, 174MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  26%|█▎   | 1.29G/4.98G [00:06<00:19, 190MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  27%|█▎   | 1.32G/4.98G [00:06<00:17, 205MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  27%|█▎   | 1.35G/4.98G [00:06<00:16, 218MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  28%|█▍   | 1.38G/4.98G [00:06<00:15, 225MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  28%|█▍   | 1.42G/4.98G [00:06<00:15, 227MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  29%|█▍   | 1.45G/4.98G [00:06<00:15, 234MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  30%|█▍   | 1.48G/4.98G [00:06<00:19, 179MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  30%|█▌   | 1.51G/4.98G [00:07<00:17, 196MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  31%|█▌   | 1.54G/4.98G [00:07<00:16, 212MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  32%|█▌   | 1.57G/4.98G [00:07<00:15, 220MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  32%|█▌   | 1.60G/4.98G [00:07<00:14, 226MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  33%|█▋   | 1.64G/4.98G [00:07<00:14, 230MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  34%|█▋   | 1.67G/4.98G [00:07<00:14, 235MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  34%|█▋   | 1.70G/4.98G [00:08<00:18, 176MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  35%|█▋   | 1.73G/4.98G [00:08<00:16, 192MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  35%|█▊   | 1.76G/4.98G [00:08<00:15, 203MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  36%|█▊   | 1.79G/4.98G [00:08<00:14, 214MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  37%|█▊   | 1.82G/4.98G [00:08<00:14, 221MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  37%|█▊   | 1.86G/4.98G [00:08<00:13, 227MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  38%|█▉   | 1.89G/4.98G [00:08<00:17, 180MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  39%|█▉   | 1.92G/4.98G [00:09<00:15, 196MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  39%|█▉   | 1.95G/4.98G [00:09<00:14, 208MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  40%|█▉   | 1.98G/4.98G [00:09<00:13, 219MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  40%|██   | 2.01G/4.98G [00:09<00:13, 228MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  41%|██   | 2.04G/4.98G [00:09<00:12, 234MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.08G/4.98G [00:09<00:12, 239MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  42%|██   | 2.11G/4.98G [00:09<00:16, 178MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  43%|██▏  | 2.13G/4.98G [00:10<00:20, 139MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  43%|██▏  | 2.15G/4.98G [00:10<00:22, 127MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  44%|██▏  | 2.17G/4.98G [00:10<00:20, 135MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  44%|██▏  | 2.20G/4.98G [00:10<00:16, 163MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  45%|██▏  | 2.23G/4.98G [00:10<00:14, 185MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  46%|██▎  | 2.26G/4.98G [00:10<00:13, 202MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  46%|██▎  | 2.30G/4.98G [00:11<00:12, 215MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  47%|██▎  | 2.33G/4.98G [00:11<00:11, 223MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  47%|██▎  | 2.36G/4.98G [00:11<00:14, 179MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  48%|██▍  | 2.38G/4.98G [00:11<00:18, 143MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  48%|██▍  | 2.40G/4.98G [00:11<00:21, 118MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  49%|██▍  | 2.42G/4.98G [00:12<00:21, 119MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  49%|██▍  | 2.44G/4.98G [00:12<00:20, 121MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  50%|██▍  | 2.46G/4.98G [00:12<00:21, 119MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  50%|██▍  | 2.49G/4.98G [00:12<00:22, 110MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  50%|██▌  | 2.51G/4.98G [00:12<00:21, 113MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  51%|██▌  | 2.53G/4.98G [00:13<00:21, 114MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  51%|██▌  | 2.55G/4.98G [00:13<00:20, 121MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  52%|██▌  | 2.57G/4.98G [00:13<00:21, 110MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  52%|██  | 2.59G/4.98G [00:13<00:23, 99.8MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  52%|██  | 2.60G/4.98G [00:13<00:25, 94.8MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  52%|██  | 2.61G/4.98G [00:13<00:25, 91.8MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  53%|██▋  | 2.63G/4.98G [00:14<00:23, 100MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  54%|██▋  | 2.66G/4.98G [00:14<00:20, 113MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  54%|██▋  | 2.68G/4.98G [00:14<00:20, 110MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  54%|██▋  | 2.71G/4.98G [00:14<00:19, 114MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  55%|██▋  | 2.73G/4.98G [00:14<00:18, 122MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  55%|██▊  | 2.75G/4.98G [00:15<00:18, 117MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  56%|██▊  | 2.77G/4.98G [00:15<00:20, 109MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  56%|██▊  | 2.79G/4.98G [00:15<00:18, 115MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  57%|██▊  | 2.82G/4.98G [00:15<00:14, 145MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  57%|██▊  | 2.85G/4.98G [00:15<00:12, 167MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  58%|██▉  | 2.88G/4.98G [00:15<00:11, 186MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  59%|██▉  | 2.92G/4.98G [00:16<00:10, 203MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  59%|██▉  | 2.95G/4.98G [00:16<00:09, 216MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  60%|██▉  | 2.98G/4.98G [00:16<00:09, 217MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  60%|███  | 3.01G/4.98G [00:16<00:08, 225MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  61%|███  | 3.04G/4.98G [00:16<00:08, 231MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  62%|███  | 3.07G/4.98G [00:16<00:08, 236MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  62%|███  | 3.10G/4.98G [00:16<00:07, 243MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  63%|███▏ | 3.14G/4.98G [00:16<00:07, 244MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  64%|███▏ | 3.17G/4.98G [00:17<00:07, 245MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  64%|███▏ | 3.20G/4.98G [00:17<00:07, 246MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  65%|███▏ | 3.23G/4.98G [00:17<00:07, 248MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  66%|███▎ | 3.26G/4.98G [00:17<00:06, 246MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  66%|███▎ | 3.29G/4.98G [00:17<00:06, 245MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  67%|███▎ | 3.32G/4.98G [00:17<00:06, 246MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  67%|███▎ | 3.36G/4.98G [00:17<00:06, 251MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  68%|███▍ | 3.39G/4.98G [00:17<00:06, 252MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  69%|███▍ | 3.42G/4.98G [00:18<00:06, 248MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  69%|███▍ | 3.45G/4.98G [00:18<00:06, 250MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  70%|███▍ | 3.48G/4.98G [00:18<00:05, 250MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  71%|███▌ | 3.51G/4.98G [00:18<00:05, 248MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  71%|███▌ | 3.54G/4.98G [00:18<00:05, 247MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  72%|███▌ | 3.58G/4.98G [00:18<00:05, 249MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  72%|███▌ | 3.61G/4.98G [00:18<00:05, 248MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  73%|███▋ | 3.64G/4.98G [00:18<00:05, 247MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 3.67G/4.98G [00:19<00:05, 226MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  74%|███▋ | 3.70G/4.98G [00:19<00:05, 230MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  75%|███▊ | 3.73G/4.98G [00:19<00:05, 246MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.76G/4.98G [00:19<00:04, 252MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  76%|███▊ | 3.80G/4.98G [00:19<00:04, 253MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  77%|███▊ | 3.83G/4.98G [00:19<00:04, 250MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  78%|███▉ | 3.86G/4.98G [00:19<00:04, 247MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  78%|███▉ | 3.89G/4.98G [00:19<00:04, 245MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.92G/4.98G [00:20<00:04, 246MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  79%|███▉ | 3.95G/4.98G [00:20<00:04, 251MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  80%|████ | 3.98G/4.98G [00:20<00:03, 257MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  81%|████ | 4.02G/4.98G [00:20<00:03, 265MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  81%|████ | 4.05G/4.98G [00:20<00:03, 260MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  82%|████ | 4.08G/4.98G [00:20<00:03, 254MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 4.11G/4.98G [00:20<00:03, 253MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 4.14G/4.98G [00:20<00:03, 251MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 4.17G/4.98G [00:21<00:03, 250MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  84%|████▏| 4.20G/4.98G [00:21<00:03, 247MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  85%|████▎| 4.24G/4.98G [00:21<00:02, 252MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  86%|████▎| 4.27G/4.98G [00:21<00:02, 253MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  86%|████▎| 4.30G/4.98G [00:21<00:02, 251MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  87%|████▎| 4.33G/4.98G [00:21<00:02, 251MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  88%|████▍| 4.36G/4.98G [00:21<00:02, 252MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  88%|████▍| 4.39G/4.98G [00:21<00:02, 249MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  89%|████▍| 4.42G/4.98G [00:22<00:03, 166MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  90%|████▍| 4.46G/4.98G [00:22<00:02, 184MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  90%|████▌| 4.49G/4.98G [00:22<00:02, 203MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  91%|████▌| 4.52G/4.98G [00:22<00:02, 217MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  91%|████▌| 4.55G/4.98G [00:22<00:01, 228MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  92%|████▌| 4.58G/4.98G [00:22<00:01, 234MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  93%|████▋| 4.61G/4.98G [00:23<00:01, 239MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  93%|████▋| 4.65G/4.98G [00:23<00:01, 239MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  94%|████▋| 4.68G/4.98G [00:23<00:01, 242MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  95%|████▋| 4.71G/4.98G [00:23<00:01, 243MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  95%|████▊| 4.74G/4.98G [00:23<00:00, 238MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  96%|████▊| 4.77G/4.98G [00:23<00:00, 233MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  96%|████▊| 4.80G/4.98G [00:23<00:00, 242MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  97%|████▊| 4.83G/4.98G [00:23<00:00, 251MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  98%|████▉| 4.87G/4.98G [00:24<00:00, 252MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  98%|████▉| 4.90G/4.98G [00:24<00:00, 252MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors:  99%|████▉| 4.93G/4.98G [00:24<00:00, 251MB/s]\u001b[A\r\n",
      "model-00001-of-00004.safetensors: 100%|█████| 4.98G/4.98G [00:24<00:00, 203MB/s]\r\n",
      "Downloading shards:  25%|██████▎                  | 1/4 [00:24<01:13, 24.65s/it]\r\n",
      "model-00002-of-00004.safetensors:   0%|             | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   0%|     | 21.0M/5.00G [00:00<00:25, 197MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   1%|     | 41.9M/5.00G [00:00<00:24, 199MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   1%|     | 73.4M/5.00G [00:00<00:22, 223MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   2%|▏     | 105M/5.00G [00:00<00:19, 246MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   3%|▏     | 136M/5.00G [00:00<00:20, 243MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   3%|▏     | 168M/5.00G [00:00<00:18, 256MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   4%|▏     | 199M/5.00G [00:00<00:19, 252MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   5%|▎     | 231M/5.00G [00:00<00:18, 252MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   5%|▎     | 262M/5.00G [00:01<00:18, 261MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   6%|▎     | 294M/5.00G [00:01<00:18, 258MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   7%|▍     | 325M/5.00G [00:01<00:17, 263MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   7%|▍     | 357M/5.00G [00:01<00:18, 256MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   8%|▍     | 388M/5.00G [00:01<00:18, 252MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   8%|▌     | 419M/5.00G [00:01<00:18, 249MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:   9%|▌     | 451M/5.00G [00:01<00:18, 252MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  10%|▌     | 482M/5.00G [00:01<00:18, 243MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  10%|▌     | 514M/5.00G [00:02<00:18, 237MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  11%|▋     | 545M/5.00G [00:02<00:18, 247MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 577M/5.00G [00:02<00:17, 254MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 608M/5.00G [00:02<00:17, 247MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  13%|▊     | 640M/5.00G [00:02<00:17, 251MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  13%|▊     | 671M/5.00G [00:02<00:17, 250MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  14%|▊     | 703M/5.00G [00:02<00:16, 254MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  15%|▉     | 734M/5.00G [00:02<00:16, 254MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  15%|▉     | 765M/5.00G [00:03<00:16, 253MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  16%|▉     | 797M/5.00G [00:03<00:16, 253MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  17%|▉     | 828M/5.00G [00:03<00:16, 254MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  17%|█     | 860M/5.00G [00:03<00:16, 244MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  18%|█     | 891M/5.00G [00:03<00:16, 244MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  18%|█     | 923M/5.00G [00:03<00:16, 249MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  19%|█▏    | 954M/5.00G [00:03<00:16, 243MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  20%|█▏    | 986M/5.00G [00:03<00:16, 239MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  20%|█    | 1.02G/5.00G [00:04<00:16, 242MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  21%|█    | 1.05G/5.00G [00:04<00:20, 192MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  21%|█    | 1.07G/5.00G [00:04<00:20, 194MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  22%|█    | 1.10G/5.00G [00:04<00:18, 208MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  23%|█▏   | 1.13G/5.00G [00:04<00:17, 217MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  23%|█▏   | 1.16G/5.00G [00:04<00:17, 220MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  24%|█▏   | 1.20G/5.00G [00:04<00:16, 228MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  25%|█▏   | 1.23G/5.00G [00:05<00:16, 226MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  25%|█▎   | 1.26G/5.00G [00:05<00:19, 189MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  26%|█▎   | 1.29G/5.00G [00:05<00:18, 203MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  26%|█▎   | 1.32G/5.00G [00:05<00:17, 214MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  27%|█▎   | 1.35G/5.00G [00:05<00:16, 223MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  28%|█▍   | 1.38G/5.00G [00:05<00:15, 233MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  28%|█▍   | 1.42G/5.00G [00:05<00:15, 235MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  29%|█▍   | 1.45G/5.00G [00:06<00:15, 231MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  30%|█▍   | 1.48G/5.00G [00:06<00:19, 179MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  30%|█▌   | 1.51G/5.00G [00:06<00:18, 192MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  31%|█▌   | 1.54G/5.00G [00:06<00:16, 207MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  31%|█▌   | 1.57G/5.00G [00:06<00:15, 216MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  32%|█▌   | 1.60G/5.00G [00:06<00:14, 228MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  33%|█▋   | 1.64G/5.00G [00:07<00:14, 239MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  33%|█▋   | 1.67G/5.00G [00:07<00:13, 239MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  34%|█▋   | 1.70G/5.00G [00:07<00:18, 176MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  35%|█▋   | 1.73G/5.00G [00:07<00:16, 194MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  35%|█▊   | 1.76G/5.00G [00:07<00:15, 207MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  36%|█▊   | 1.79G/5.00G [00:07<00:14, 216MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  36%|█▊   | 1.82G/5.00G [00:07<00:14, 224MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  37%|█▊   | 1.86G/5.00G [00:08<00:13, 226MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  38%|█▉   | 1.89G/5.00G [00:08<00:17, 180MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  38%|█▉   | 1.92G/5.00G [00:08<00:15, 196MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  39%|█▉   | 1.95G/5.00G [00:08<00:14, 210MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  40%|█▉   | 1.98G/5.00G [00:08<00:13, 218MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  40%|██   | 2.01G/5.00G [00:08<00:13, 227MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  41%|██   | 2.04G/5.00G [00:08<00:12, 235MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  42%|██   | 2.08G/5.00G [00:09<00:12, 238MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  42%|██   | 2.11G/5.00G [00:09<00:16, 178MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  43%|██▏  | 2.14G/5.00G [00:09<00:14, 194MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  43%|██▏  | 2.17G/5.00G [00:09<00:13, 204MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  44%|██▏  | 2.20G/5.00G [00:09<00:12, 219MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  45%|██▏  | 2.23G/5.00G [00:09<00:12, 215MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  45%|██▎  | 2.26G/5.00G [00:10<00:18, 152MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  46%|██▎  | 2.29G/5.00G [00:10<00:17, 153MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  46%|██▎  | 2.31G/5.00G [00:10<00:22, 118MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  47%|██▎  | 2.33G/5.00G [00:10<00:21, 127MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  47%|██▎  | 2.35G/5.00G [00:11<00:24, 109MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  47%|██▎  | 2.37G/5.00G [00:11<00:22, 118MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  48%|█▉  | 2.39G/5.00G [00:11<00:27, 94.2MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  48%|██▍  | 2.41G/5.00G [00:11<00:23, 109MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  49%|██▍  | 2.43G/5.00G [00:11<00:25, 100MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  49%|█▉  | 2.45G/5.00G [00:12<00:28, 90.9MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  49%|█▉  | 2.47G/5.00G [00:12<00:27, 91.6MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  50%|█▉  | 2.49G/5.00G [00:12<00:28, 88.0MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  50%|█▉  | 2.50G/5.00G [00:12<00:30, 82.9MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  50%|██  | 2.51G/5.00G [00:12<00:30, 80.7MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  50%|██  | 2.52G/5.00G [00:13<00:29, 84.8MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.54G/5.00G [00:13<00:23, 103MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  51%|██▌  | 2.56G/5.00G [00:13<00:20, 117MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  52%|██  | 2.58G/5.00G [00:13<00:26, 90.0MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  52%|██  | 2.60G/5.00G [00:13<00:28, 82.8MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  52%|██  | 2.61G/5.00G [00:14<00:33, 71.6MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  52%|██  | 2.62G/5.00G [00:14<00:32, 73.3MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  53%|██  | 2.63G/5.00G [00:14<00:31, 75.6MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  53%|██  | 2.64G/5.00G [00:14<00:34, 68.8MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  53%|██▋  | 2.67G/5.00G [00:14<00:21, 109MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  54%|██▋  | 2.71G/5.00G [00:14<00:16, 143MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  55%|██▋  | 2.74G/5.00G [00:14<00:13, 169MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  55%|██▊  | 2.77G/5.00G [00:15<00:11, 190MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  56%|██▊  | 2.80G/5.00G [00:15<00:10, 204MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  57%|██▊  | 2.83G/5.00G [00:15<00:10, 199MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  57%|██▊  | 2.86G/5.00G [00:15<00:10, 206MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  58%|██▉  | 2.89G/5.00G [00:15<00:09, 215MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  59%|██▉  | 2.93G/5.00G [00:15<00:09, 224MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  59%|██▉  | 2.96G/5.00G [00:15<00:08, 235MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  60%|██▉  | 2.99G/5.00G [00:16<00:08, 246MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  60%|███  | 3.02G/5.00G [00:16<00:08, 245MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  61%|███  | 3.05G/5.00G [00:16<00:07, 248MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  62%|███  | 3.08G/5.00G [00:16<00:07, 247MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  62%|███  | 3.11G/5.00G [00:16<00:07, 246MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  63%|███▏ | 3.15G/5.00G [00:16<00:07, 233MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  64%|███▏ | 3.18G/5.00G [00:16<00:07, 234MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  64%|███▏ | 3.21G/5.00G [00:16<00:07, 236MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  65%|███▏ | 3.24G/5.00G [00:17<00:07, 238MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  65%|███▎ | 3.27G/5.00G [00:17<00:07, 225MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  66%|███▎ | 3.30G/5.00G [00:17<00:07, 226MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  67%|███▎ | 3.33G/5.00G [00:17<00:07, 228MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  67%|███▎ | 3.37G/5.00G [00:17<00:07, 233MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  68%|███▍ | 3.40G/5.00G [00:17<00:07, 226MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 3.43G/5.00G [00:17<00:06, 229MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  69%|███▍ | 3.46G/5.00G [00:18<00:06, 232MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  70%|███▍ | 3.49G/5.00G [00:18<00:06, 240MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  70%|███▌ | 3.52G/5.00G [00:18<00:05, 251MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  71%|███▌ | 3.55G/5.00G [00:18<00:05, 259MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  72%|███▌ | 3.59G/5.00G [00:18<00:05, 255MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  72%|███▌ | 3.62G/5.00G [00:18<00:05, 256MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  73%|███▋ | 3.65G/5.00G [00:18<00:05, 244MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 3.68G/5.00G [00:18<00:06, 218MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  74%|███▋ | 3.71G/5.00G [00:19<00:05, 222MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  75%|███▋ | 3.74G/5.00G [00:19<00:05, 219MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  76%|███▊ | 3.77G/5.00G [00:19<00:05, 221MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  76%|███▊ | 3.81G/5.00G [00:19<00:05, 235MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 3.84G/5.00G [00:19<00:04, 246MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  77%|███▊ | 3.87G/5.00G [00:19<00:04, 249MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  78%|███▉ | 3.90G/5.00G [00:19<00:04, 238MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.93G/5.00G [00:20<00:04, 237MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  79%|███▉ | 3.96G/5.00G [00:20<00:04, 243MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  80%|███▉ | 4.00G/5.00G [00:20<00:04, 240MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  81%|████ | 4.03G/5.00G [00:20<00:06, 159MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  81%|████ | 4.06G/5.00G [00:20<00:05, 181MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  82%|████ | 4.09G/5.00G [00:20<00:04, 196MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  82%|████ | 4.12G/5.00G [00:21<00:04, 207MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  83%|████▏| 4.15G/5.00G [00:21<00:03, 223MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  84%|████▏| 4.18G/5.00G [00:21<00:03, 225MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  84%|████▏| 4.22G/5.00G [00:21<00:03, 233MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  85%|████▏| 4.25G/5.00G [00:21<00:03, 246MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  86%|████▎| 4.28G/5.00G [00:21<00:02, 255MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  86%|████▎| 4.31G/5.00G [00:21<00:02, 238MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  87%|████▎| 4.34G/5.00G [00:21<00:03, 216MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  87%|████▎| 4.37G/5.00G [00:22<00:03, 206MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  88%|████▍| 4.40G/5.00G [00:22<00:02, 205MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.44G/5.00G [00:22<00:02, 218MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  89%|████▍| 4.47G/5.00G [00:22<00:02, 227MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  90%|████▍| 4.50G/5.00G [00:22<00:02, 227MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  91%|████▌| 4.53G/5.00G [00:22<00:02, 230MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  91%|████▌| 4.56G/5.00G [00:22<00:01, 232MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  92%|████▌| 4.59G/5.00G [00:23<00:01, 234MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  92%|████▌| 4.62G/5.00G [00:23<00:01, 243MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  93%|████▋| 4.66G/5.00G [00:23<00:01, 254MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  94%|████▋| 4.69G/5.00G [00:23<00:01, 258MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  94%|████▋| 4.72G/5.00G [00:23<00:01, 256MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  95%|████▊| 4.75G/5.00G [00:23<00:01, 236MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  96%|████▊| 4.78G/5.00G [00:23<00:01, 217MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  96%|████▊| 4.81G/5.00G [00:24<00:00, 220MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  97%|████▊| 4.84G/5.00G [00:24<00:00, 225MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  98%|████▉| 4.88G/5.00G [00:24<00:00, 222MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  98%|████▉| 4.91G/5.00G [00:24<00:00, 227MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  99%|████▉| 4.94G/5.00G [00:24<00:00, 230MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors:  99%|████▉| 4.97G/5.00G [00:24<00:00, 224MB/s]\u001b[A\r\n",
      "model-00002-of-00004.safetensors: 100%|█████| 5.00G/5.00G [00:24<00:00, 201MB/s]\r\n",
      "Downloading shards:  50%|████████████▌            | 2/4 [00:49<00:49, 24.82s/it]\r\n",
      "model-00003-of-00004.safetensors:   0%|             | 0.00/4.92G [00:00<?, ?B/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   0%|     | 10.5M/4.92G [00:00<00:47, 104MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   1%|     | 41.9M/4.92G [00:00<00:24, 197MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   1%|     | 73.4M/4.92G [00:00<00:20, 234MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   2%|▏     | 105M/4.92G [00:00<00:19, 245MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   3%|▏     | 136M/4.92G [00:00<00:19, 242MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   3%|▏     | 168M/4.92G [00:00<00:19, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   4%|▏     | 199M/4.92G [00:00<00:19, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   5%|▎     | 231M/4.92G [00:00<00:19, 239MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   5%|▎    | 262M/4.92G [00:02<01:28, 52.8MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   6%|▎    | 283M/4.92G [00:02<01:17, 59.6MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   6%|▎    | 315M/4.92G [00:02<00:58, 79.1MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   7%|▍     | 346M/4.92G [00:03<00:44, 102MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   8%|▍     | 377M/4.92G [00:03<00:36, 124MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   8%|▍     | 409M/4.92G [00:03<00:30, 147MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:   9%|▌     | 440M/4.92G [00:03<00:26, 168MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  10%|▌     | 472M/4.92G [00:03<00:23, 186MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  10%|▌     | 503M/4.92G [00:03<00:22, 200MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  11%|▋     | 535M/4.92G [00:03<00:20, 212MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  12%|▋     | 566M/4.92G [00:03<00:19, 220MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  12%|▋     | 598M/4.92G [00:04<00:19, 226MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  13%|▊     | 629M/4.92G [00:04<00:18, 233MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  13%|▋    | 661M/4.92G [00:05<01:11, 59.2MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  14%|▋    | 682M/4.92G [00:05<01:01, 69.1MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  15%|▋    | 713M/4.92G [00:05<00:46, 90.2MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  15%|▉     | 744M/4.92G [00:06<00:36, 114MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  16%|▉     | 776M/4.92G [00:06<00:29, 139MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  16%|▉     | 807M/4.92G [00:06<00:25, 162MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  17%|█     | 839M/4.92G [00:06<00:22, 182MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  18%|█     | 870M/4.92G [00:06<00:20, 196MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  18%|█     | 902M/4.92G [00:06<00:19, 209MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  19%|█▏    | 933M/4.92G [00:06<00:18, 221MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  20%|█▏    | 965M/4.92G [00:06<00:17, 227MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  20%|█▏    | 996M/4.92G [00:07<00:16, 234MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  21%|█    | 1.03G/4.92G [00:07<00:16, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  22%|█    | 1.06G/4.92G [00:07<00:15, 247MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  22%|█    | 1.09G/4.92G [00:07<00:15, 246MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  23%|█▏   | 1.12G/4.92G [00:07<00:15, 243MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  23%|█▏   | 1.15G/4.92G [00:07<00:15, 242MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  24%|█▏   | 1.18G/4.92G [00:07<00:14, 251MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  25%|█▏   | 1.22G/4.92G [00:07<00:14, 249MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  25%|█▎   | 1.25G/4.92G [00:08<00:15, 243MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  26%|█▎   | 1.28G/4.92G [00:08<00:14, 243MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  27%|█▎   | 1.31G/4.92G [00:08<00:15, 232MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  27%|█▎   | 1.34G/4.92G [00:08<00:14, 239MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  28%|█▍   | 1.37G/4.92G [00:08<00:14, 247MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  29%|█▍   | 1.41G/4.92G [00:08<00:13, 256MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  29%|█▍   | 1.44G/4.92G [00:08<00:13, 259MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  30%|█▍   | 1.47G/4.92G [00:08<00:13, 255MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  31%|█▌   | 1.50G/4.92G [00:09<00:13, 253MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  31%|█▌   | 1.53G/4.92G [00:09<00:13, 251MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  32%|█▌   | 1.56G/4.92G [00:09<00:13, 246MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  32%|█▌   | 1.59G/4.92G [00:09<00:13, 245MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  33%|█▋   | 1.63G/4.92G [00:09<00:13, 244MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  34%|█▎  | 1.66G/4.92G [00:12<01:32, 35.2MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  34%|█▎  | 1.68G/4.92G [00:12<01:18, 41.2MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  35%|█▍  | 1.71G/4.92G [00:12<00:57, 56.1MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  35%|█▍  | 1.74G/4.92G [00:12<00:42, 75.1MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  36%|█▍  | 1.77G/4.92G [00:12<00:33, 95.2MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  37%|█▊   | 1.80G/4.92G [00:13<00:27, 112MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  37%|█▊   | 1.84G/4.92G [00:13<00:22, 134MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  38%|█▉   | 1.87G/4.92G [00:13<00:19, 154MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  39%|█▉   | 1.90G/4.92G [00:13<00:17, 174MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  39%|█▉   | 1.93G/4.92G [00:13<00:15, 192MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  40%|█▉   | 1.96G/4.92G [00:13<00:14, 204MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  41%|██   | 1.99G/4.92G [00:13<00:13, 215MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  41%|██   | 2.02G/4.92G [00:13<00:12, 224MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  42%|██   | 2.06G/4.92G [00:14<00:12, 224MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  42%|██   | 2.09G/4.92G [00:14<00:12, 229MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  43%|██▏  | 2.12G/4.92G [00:14<00:12, 232MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  44%|██▏  | 2.15G/4.92G [00:14<00:11, 234MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  44%|██▏  | 2.18G/4.92G [00:14<00:11, 235MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  45%|██▎  | 2.21G/4.92G [00:14<00:11, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  46%|██▎  | 2.24G/4.92G [00:14<00:11, 238MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  46%|██▎  | 2.28G/4.92G [00:14<00:10, 242MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  47%|██▎  | 2.31G/4.92G [00:15<00:10, 245MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  48%|██▍  | 2.34G/4.92G [00:15<00:10, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  48%|██▍  | 2.37G/4.92G [00:15<00:10, 238MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  49%|██▍  | 2.40G/4.92G [00:15<00:10, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  49%|██▍  | 2.43G/4.92G [00:15<00:10, 242MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  50%|██▌  | 2.46G/4.92G [00:15<00:10, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  51%|██▌  | 2.50G/4.92G [00:15<00:10, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  51%|██▌  | 2.53G/4.92G [00:16<00:09, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  52%|██▌  | 2.56G/4.92G [00:16<00:09, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  53%|██▋  | 2.59G/4.92G [00:16<00:09, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  53%|██▋  | 2.62G/4.92G [00:16<00:09, 239MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  54%|██▋  | 2.65G/4.92G [00:16<00:10, 220MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  55%|██▋  | 2.68G/4.92G [00:16<00:09, 227MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  55%|██▊  | 2.72G/4.92G [00:16<00:09, 233MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  56%|██▊  | 2.75G/4.92G [00:16<00:09, 236MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  57%|██▊  | 2.78G/4.92G [00:17<00:08, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  57%|██▊  | 2.81G/4.92G [00:17<00:08, 243MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  58%|██▉  | 2.84G/4.92G [00:17<00:08, 243MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  58%|██▉  | 2.87G/4.92G [00:17<00:08, 242MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  59%|██▉  | 2.90G/4.92G [00:17<00:08, 244MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  60%|██▉  | 2.94G/4.92G [00:17<00:08, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  60%|███  | 2.97G/4.92G [00:17<00:08, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  61%|███  | 3.00G/4.92G [00:17<00:07, 244MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  62%|███  | 3.03G/4.92G [00:18<00:07, 243MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  62%|███  | 3.06G/4.92G [00:18<00:07, 245MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  63%|███▏ | 3.09G/4.92G [00:18<00:07, 247MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  64%|███▏ | 3.12G/4.92G [00:18<00:07, 247MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  64%|███▏ | 3.16G/4.92G [00:18<00:07, 246MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  65%|███▏ | 3.19G/4.92G [00:18<00:06, 250MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  65%|███▎ | 3.22G/4.92G [00:18<00:06, 248MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  66%|███▎ | 3.25G/4.92G [00:19<00:06, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  67%|███▎ | 3.28G/4.92G [00:19<00:06, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  67%|███▎ | 3.31G/4.92G [00:19<00:06, 243MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  68%|███▍ | 3.34G/4.92G [00:19<00:06, 242MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  69%|███▍ | 3.38G/4.92G [00:19<00:06, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  69%|███▍ | 3.41G/4.92G [00:19<00:06, 243MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  70%|███▍ | 3.44G/4.92G [00:19<00:06, 245MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  71%|███▌ | 3.47G/4.92G [00:19<00:05, 246MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  71%|███▌ | 3.50G/4.92G [00:20<00:05, 246MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  72%|███▌ | 3.53G/4.92G [00:20<00:05, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  73%|███▋ | 3.57G/4.92G [00:20<00:05, 227MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  73%|███▋ | 3.60G/4.92G [00:20<00:05, 233MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  74%|███▋ | 3.63G/4.92G [00:20<00:05, 237MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  74%|███▋ | 3.66G/4.92G [00:20<00:05, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  75%|███▊ | 3.69G/4.92G [00:20<00:05, 236MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  76%|███▊ | 3.72G/4.92G [00:20<00:05, 237MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  76%|███▊ | 3.75G/4.92G [00:21<00:04, 240MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  77%|███▊ | 3.79G/4.92G [00:21<00:04, 239MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  78%|███▉ | 3.82G/4.92G [00:21<00:04, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  78%|███▉ | 3.85G/4.92G [00:21<00:04, 244MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  79%|███▉ | 3.88G/4.92G [00:21<00:04, 243MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  80%|███▉ | 3.91G/4.92G [00:21<00:04, 239MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  80%|████ | 3.94G/4.92G [00:21<00:04, 220MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  81%|████ | 3.97G/4.92G [00:22<00:04, 222MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  81%|████ | 4.01G/4.92G [00:22<00:04, 226MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  82%|████ | 4.04G/4.92G [00:22<00:03, 230MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  83%|████▏| 4.07G/4.92G [00:22<00:03, 232MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  83%|████▏| 4.10G/4.92G [00:22<00:03, 235MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  84%|████▏| 4.13G/4.92G [00:22<00:03, 236MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  85%|████▏| 4.16G/4.92G [00:22<00:03, 238MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  85%|████▎| 4.19G/4.92G [00:22<00:02, 241MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  86%|████▎| 4.23G/4.92G [00:23<00:04, 166MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  87%|████▎| 4.26G/4.92G [00:23<00:03, 187MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  87%|████▎| 4.29G/4.92G [00:23<00:03, 206MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  88%|████▍| 4.32G/4.92G [00:23<00:02, 220MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  89%|████▍| 4.35G/4.92G [00:23<00:02, 228MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  89%|████▍| 4.38G/4.92G [00:23<00:02, 222MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  90%|████▍| 4.41G/4.92G [00:24<00:02, 234MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  90%|████▌| 4.45G/4.92G [00:24<00:01, 244MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  91%|████▌| 4.48G/4.92G [00:24<00:01, 248MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  92%|████▌| 4.51G/4.92G [00:24<00:01, 256MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  92%|████▌| 4.54G/4.92G [00:24<00:01, 257MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  93%|████▋| 4.57G/4.92G [00:24<00:01, 249MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  94%|████▋| 4.60G/4.92G [00:24<00:01, 252MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  94%|████▋| 4.63G/4.92G [00:24<00:01, 248MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  95%|████▋| 4.67G/4.92G [00:25<00:00, 251MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  96%|████▊| 4.70G/4.92G [00:25<00:00, 248MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  96%|████▊| 4.73G/4.92G [00:25<00:00, 249MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  97%|████▊| 4.76G/4.92G [00:25<00:00, 248MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  97%|████▊| 4.79G/4.92G [00:25<00:00, 246MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  98%|████▉| 4.82G/4.92G [00:25<00:00, 245MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  99%|████▉| 4.85G/4.92G [00:25<00:00, 246MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors:  99%|████▉| 4.89G/4.92G [00:25<00:00, 244MB/s]\u001b[A\r\n",
      "model-00003-of-00004.safetensors: 100%|█████| 4.92G/4.92G [00:26<00:00, 188MB/s]\r\n",
      "Downloading shards:  75%|██████████████████▊      | 3/4 [01:15<00:25, 25.48s/it]\r\n",
      "model-00004-of-00004.safetensors:   0%|             | 0.00/1.17G [00:00<?, ?B/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:   2%|     | 21.0M/1.17G [00:00<00:08, 138MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:   4%|▏    | 41.9M/1.17G [00:00<00:06, 167MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:   6%|▎    | 73.4M/1.17G [00:00<00:05, 204MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:   9%|▌     | 105M/1.17G [00:00<00:04, 229MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  12%|▋     | 136M/1.17G [00:00<00:04, 230MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  14%|▊     | 168M/1.17G [00:00<00:04, 241MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  17%|█     | 199M/1.17G [00:00<00:03, 251MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  20%|█▏    | 231M/1.17G [00:00<00:03, 254MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  22%|█▎    | 262M/1.17G [00:01<00:03, 247MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  25%|█▌    | 294M/1.17G [00:01<00:03, 243MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  28%|█▋    | 325M/1.17G [00:01<00:03, 244MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  31%|█▊    | 357M/1.17G [00:01<00:03, 247MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  33%|█▉    | 388M/1.17G [00:01<00:03, 236MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  36%|██▏   | 419M/1.17G [00:01<00:03, 238MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  39%|██▎   | 451M/1.17G [00:01<00:02, 249MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  41%|██▍   | 482M/1.17G [00:02<00:02, 252MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  44%|██▋   | 514M/1.17G [00:02<00:02, 254MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  47%|██▊   | 545M/1.17G [00:02<00:02, 250MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  49%|██▉   | 577M/1.17G [00:02<00:02, 239MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  52%|███   | 608M/1.17G [00:02<00:02, 239MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  55%|███▎  | 640M/1.17G [00:02<00:02, 236MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  57%|███▍  | 671M/1.17G [00:02<00:02, 232MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  60%|███▌  | 703M/1.17G [00:02<00:01, 234MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  63%|███▊  | 734M/1.17G [00:03<00:01, 241MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  66%|███▉  | 765M/1.17G [00:03<00:01, 242MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  68%|████  | 797M/1.17G [00:03<00:01, 240MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  71%|████▎ | 828M/1.17G [00:03<00:01, 242MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  74%|████▍ | 860M/1.17G [00:03<00:01, 229MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  76%|████▌ | 891M/1.17G [00:03<00:01, 221MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  79%|████▋ | 923M/1.17G [00:03<00:01, 236MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  82%|████▉ | 954M/1.17G [00:03<00:00, 253MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  84%|█████ | 986M/1.17G [00:04<00:00, 248MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  87%|████▎| 1.02G/1.17G [00:04<00:00, 249MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  90%|████▍| 1.05G/1.17G [00:04<00:00, 246MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  92%|████▌| 1.08G/1.17G [00:04<00:00, 247MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  95%|████▊| 1.11G/1.17G [00:04<00:00, 242MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors:  98%|████▉| 1.14G/1.17G [00:04<00:00, 246MB/s]\u001b[A\r\n",
      "model-00004-of-00004.safetensors: 100%|█████| 1.17G/1.17G [00:04<00:00, 239MB/s]\r\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [01:20<00:00, 20.20s/it]\r\n",
      "Downloading shards: 100%|█████████████████████████| 4/4 [01:20<00:00, 20.21s/it]\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [01:23<00:00, 20.88s/it]\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [01:23<00:00, 20.89s/it]\r\n",
      "generation_config.json: 100%|██████████████████| 235/235 [00:00<00:00, 1.48MB/s]\r\n",
      "tokenizer_config.json: 100%|███████████████| 50.6k/50.6k [00:00<00:00, 5.02MB/s]\r\n",
      "tokenizer.json: 100%|██████████████████████| 17.2M/17.2M [00:00<00:00, 59.7MB/s]\r\n",
      "special_tokens_map.json: 100%|█████████████████| 459/459 [00:00<00:00, 3.74MB/s]\r\n",
      "unified_chip2.jsonl: 100%|██████████████████| 95.6M/95.6M [00:00<00:00, 211MB/s]\r\n",
      "Generating train split: 210289 examples [00:00, 328991.62 examples/s]\r\n",
      "Converting train dataset to ChatML (num_proc=4): 100%|█| 21029/21029 [00:00<00:0\r\n",
      "Applying chat template to train dataset (num_proc=4): 100%|█| 21029/21029 [00:03\r\n",
      "Tokenizing train dataset (num_proc=4): 100%|█| 21029/21029 [00:07<00:00, 2949.64\r\n",
      "Truncating train dataset (num_proc=4): 100%|█| 21029/21029 [00:02<00:00, 8313.35\r\n",
      "Model Summary:\r\n",
      "PeftModelForCausalLM(\r\n",
      "  (base_model): LoraModel(\r\n",
      "    (model): LlamaForCausalLM(\r\n",
      "      (model): LlamaModel(\r\n",
      "        (embed_tokens): Embedding(128256, 4096, padding_idx=128004)\r\n",
      "        (layers): ModuleList(\r\n",
      "          (0-31): 32 x LlamaDecoderLayer(\r\n",
      "            (self_attn): LlamaAttention(\r\n",
      "              (q_proj): lora.Linear4bit(\r\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\r\n",
      "                (lora_dropout): ModuleDict(\r\n",
      "                  (default): Identity()\r\n",
      "                )\r\n",
      "                (lora_A): ModuleDict(\r\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\r\n",
      "                )\r\n",
      "                (lora_B): ModuleDict(\r\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\r\n",
      "                )\r\n",
      "                (lora_embedding_A): ParameterDict()\r\n",
      "                (lora_embedding_B): ParameterDict()\r\n",
      "                (lora_magnitude_vector): ModuleDict()\r\n",
      "              )\r\n",
      "              (k_proj): lora.Linear4bit(\r\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\r\n",
      "                (lora_dropout): ModuleDict(\r\n",
      "                  (default): Identity()\r\n",
      "                )\r\n",
      "                (lora_A): ModuleDict(\r\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\r\n",
      "                )\r\n",
      "                (lora_B): ModuleDict(\r\n",
      "                  (default): Linear(in_features=64, out_features=1024, bias=False)\r\n",
      "                )\r\n",
      "                (lora_embedding_A): ParameterDict()\r\n",
      "                (lora_embedding_B): ParameterDict()\r\n",
      "                (lora_magnitude_vector): ModuleDict()\r\n",
      "              )\r\n",
      "              (v_proj): lora.Linear4bit(\r\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\r\n",
      "                (lora_dropout): ModuleDict(\r\n",
      "                  (default): Identity()\r\n",
      "                )\r\n",
      "                (lora_A): ModuleDict(\r\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\r\n",
      "                )\r\n",
      "                (lora_B): ModuleDict(\r\n",
      "                  (default): Linear(in_features=64, out_features=1024, bias=False)\r\n",
      "                )\r\n",
      "                (lora_embedding_A): ParameterDict()\r\n",
      "                (lora_embedding_B): ParameterDict()\r\n",
      "                (lora_magnitude_vector): ModuleDict()\r\n",
      "              )\r\n",
      "              (o_proj): lora.Linear4bit(\r\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\r\n",
      "                (lora_dropout): ModuleDict(\r\n",
      "                  (default): Identity()\r\n",
      "                )\r\n",
      "                (lora_A): ModuleDict(\r\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\r\n",
      "                )\r\n",
      "                (lora_B): ModuleDict(\r\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\r\n",
      "                )\r\n",
      "                (lora_embedding_A): ParameterDict()\r\n",
      "                (lora_embedding_B): ParameterDict()\r\n",
      "                (lora_magnitude_vector): ModuleDict()\r\n",
      "              )\r\n",
      "            )\r\n",
      "            (mlp): LlamaMLP(\r\n",
      "              (gate_proj): lora.Linear4bit(\r\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\r\n",
      "                (lora_dropout): ModuleDict(\r\n",
      "                  (default): Identity()\r\n",
      "                )\r\n",
      "                (lora_A): ModuleDict(\r\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\r\n",
      "                )\r\n",
      "                (lora_B): ModuleDict(\r\n",
      "                  (default): Linear(in_features=64, out_features=14336, bias=False)\r\n",
      "                )\r\n",
      "                (lora_embedding_A): ParameterDict()\r\n",
      "                (lora_embedding_B): ParameterDict()\r\n",
      "                (lora_magnitude_vector): ModuleDict()\r\n",
      "              )\r\n",
      "              (up_proj): lora.Linear4bit(\r\n",
      "                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\r\n",
      "                (lora_dropout): ModuleDict(\r\n",
      "                  (default): Identity()\r\n",
      "                )\r\n",
      "                (lora_A): ModuleDict(\r\n",
      "                  (default): Linear(in_features=4096, out_features=64, bias=False)\r\n",
      "                )\r\n",
      "                (lora_B): ModuleDict(\r\n",
      "                  (default): Linear(in_features=64, out_features=14336, bias=False)\r\n",
      "                )\r\n",
      "                (lora_embedding_A): ParameterDict()\r\n",
      "                (lora_embedding_B): ParameterDict()\r\n",
      "                (lora_magnitude_vector): ModuleDict()\r\n",
      "              )\r\n",
      "              (down_proj): lora.Linear4bit(\r\n",
      "                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\r\n",
      "                (lora_dropout): ModuleDict(\r\n",
      "                  (default): Identity()\r\n",
      "                )\r\n",
      "                (lora_A): ModuleDict(\r\n",
      "                  (default): Linear(in_features=14336, out_features=64, bias=False)\r\n",
      "                )\r\n",
      "                (lora_B): ModuleDict(\r\n",
      "                  (default): Linear(in_features=64, out_features=4096, bias=False)\r\n",
      "                )\r\n",
      "                (lora_embedding_A): ParameterDict()\r\n",
      "                (lora_embedding_B): ParameterDict()\r\n",
      "                (lora_magnitude_vector): ModuleDict()\r\n",
      "              )\r\n",
      "              (act_fn): SiLU()\r\n",
      "            )\r\n",
      "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\r\n",
      "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\r\n",
      "          )\r\n",
      "        )\r\n",
      "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\r\n",
      "        (rotary_emb): LlamaRotaryEmbedding()\r\n",
      "      )\r\n",
      "      (lm_head): Linear(in_features=4096, out_features=128256, bias=False)\r\n",
      "    )\r\n",
      "  )\r\n",
      ")\r\n",
      "trainable params: 167,772,160 || all params: 8,198,033,408 || trainable%: 2.0465\r\n",
      "trainable params: 167,772,160 || all params: 8,198,033,408 || trainable%: 2.0465\r\n",
      "{'loss': 2.1633, 'grad_norm': 3.2258408069610596, 'learning_rate': 2e-05, 'mean_token_accuracy': 0.5723876953125, 'epoch': 0.0}\r\n",
      "{'loss': 2.2829, 'grad_norm': 3.351170539855957, 'learning_rate': 1.97979797979798e-05, 'mean_token_accuracy': 0.5169677734375, 'epoch': 0.0}\r\n",
      "{'loss': 1.9318, 'grad_norm': 1.8338289260864258, 'learning_rate': 1.9595959595959596e-05, 'mean_token_accuracy': 0.5750732421875, 'epoch': 0.0}\r\n",
      "{'loss': 1.6893, 'grad_norm': 1.882015585899353, 'learning_rate': 1.9393939393939395e-05, 'mean_token_accuracy': 0.589599609375, 'epoch': 0.0}\r\n",
      "{'loss': 1.6916, 'grad_norm': 1.9095817804336548, 'learning_rate': 1.9191919191919194e-05, 'mean_token_accuracy': 0.609130859375, 'epoch': 0.0}\r\n",
      "{'loss': 1.6587, 'grad_norm': 1.3929493427276611, 'learning_rate': 1.8989898989898993e-05, 'mean_token_accuracy': 0.591552734375, 'epoch': 0.0}\r\n",
      "{'loss': 1.7729, 'grad_norm': 1.5579525232315063, 'learning_rate': 1.8787878787878792e-05, 'mean_token_accuracy': 0.5943603515625, 'epoch': 0.01}\r\n",
      "{'loss': 1.7812, 'grad_norm': 11.14289665222168, 'learning_rate': 1.8585858585858588e-05, 'mean_token_accuracy': 0.5755615234375, 'epoch': 0.01}\r\n",
      "{'loss': 1.5203, 'grad_norm': 1.339157223701477, 'learning_rate': 1.8383838383838387e-05, 'mean_token_accuracy': 0.6087646484375, 'epoch': 0.01}\r\n",
      "{'loss': 1.2449, 'grad_norm': 1.6052782535552979, 'learning_rate': 1.8181818181818182e-05, 'mean_token_accuracy': 0.6595458984375, 'epoch': 0.01}\r\n",
      "{'loss': 1.6986, 'grad_norm': 1.3837649822235107, 'learning_rate': 1.797979797979798e-05, 'mean_token_accuracy': 0.623291015625, 'epoch': 0.01}\r\n",
      "{'loss': 1.8249, 'grad_norm': 1.3710596561431885, 'learning_rate': 1.7777777777777777e-05, 'mean_token_accuracy': 0.578369140625, 'epoch': 0.01}\r\n",
      "{'loss': 1.4543, 'grad_norm': 1.0894148349761963, 'learning_rate': 1.7575757575757576e-05, 'mean_token_accuracy': 0.632080078125, 'epoch': 0.01}\r\n",
      "{'loss': 1.5918, 'grad_norm': 1.3620144128799438, 'learning_rate': 1.7373737373737375e-05, 'mean_token_accuracy': 0.6383056640625, 'epoch': 0.01}\r\n",
      "{'loss': 1.8184, 'grad_norm': 1.1146403551101685, 'learning_rate': 1.7171717171717173e-05, 'mean_token_accuracy': 0.5904541015625, 'epoch': 0.01}\r\n",
      "{'loss': 1.6859, 'grad_norm': 1.0910974740982056, 'learning_rate': 1.6969696969696972e-05, 'mean_token_accuracy': 0.591552734375, 'epoch': 0.01}\r\n",
      "{'loss': 1.4555, 'grad_norm': 1.057322382926941, 'learning_rate': 1.6767676767676768e-05, 'mean_token_accuracy': 0.6275634765625, 'epoch': 0.01}\r\n",
      "{'loss': 1.8994, 'grad_norm': 1.2195656299591064, 'learning_rate': 1.6565656565656567e-05, 'mean_token_accuracy': 0.5723876953125, 'epoch': 0.01}\r\n",
      "{'loss': 1.6548, 'grad_norm': 1.136702060699463, 'learning_rate': 1.6363636363636366e-05, 'mean_token_accuracy': 0.6070556640625, 'epoch': 0.01}\r\n",
      "{'loss': 1.5934, 'grad_norm': 1.6251730918884277, 'learning_rate': 1.616161616161616e-05, 'mean_token_accuracy': 0.6224365234375, 'epoch': 0.02}\r\n",
      "{'loss': 1.5112, 'grad_norm': 1.3520411252975464, 'learning_rate': 1.595959595959596e-05, 'mean_token_accuracy': 0.6578369140625, 'epoch': 0.02}\r\n",
      "{'loss': 1.5449, 'grad_norm': 1.2118184566497803, 'learning_rate': 1.575757575757576e-05, 'mean_token_accuracy': 0.62744140625, 'epoch': 0.02}\r\n",
      "{'loss': 1.6199, 'grad_norm': 1.1482702493667603, 'learning_rate': 1.555555555555556e-05, 'mean_token_accuracy': 0.596923828125, 'epoch': 0.02}\r\n",
      "{'loss': 1.4739, 'grad_norm': 1.0543980598449707, 'learning_rate': 1.5353535353535354e-05, 'mean_token_accuracy': 0.6168212890625, 'epoch': 0.02}\r\n",
      "{'loss': 1.5688, 'grad_norm': 1.1194968223571777, 'learning_rate': 1.5151515151515153e-05, 'mean_token_accuracy': 0.607666015625, 'epoch': 0.02}\r\n",
      "{'loss': 1.6771, 'grad_norm': 1.129153847694397, 'learning_rate': 1.4949494949494952e-05, 'mean_token_accuracy': 0.6329345703125, 'epoch': 0.02}\r\n",
      "{'loss': 1.6192, 'grad_norm': 1.1358933448791504, 'learning_rate': 1.4747474747474747e-05, 'mean_token_accuracy': 0.6151123046875, 'epoch': 0.02}\r\n",
      "{'loss': 1.2914, 'grad_norm': 1.1764558553695679, 'learning_rate': 1.4545454545454546e-05, 'mean_token_accuracy': 0.6546630859375, 'epoch': 0.02}\r\n",
      "{'loss': 1.5569, 'grad_norm': 1.4194132089614868, 'learning_rate': 1.4343434343434344e-05, 'mean_token_accuracy': 0.63232421875, 'epoch': 0.02}\r\n",
      "{'loss': 1.4385, 'grad_norm': 1.2518806457519531, 'learning_rate': 1.4141414141414143e-05, 'mean_token_accuracy': 0.6441650390625, 'epoch': 0.02}\r\n",
      "{'loss': 1.7092, 'grad_norm': 1.206908106803894, 'learning_rate': 1.3939393939393942e-05, 'mean_token_accuracy': 0.6087646484375, 'epoch': 0.02}\r\n",
      "{'loss': 1.4187, 'grad_norm': 1.3032898902893066, 'learning_rate': 1.3737373737373739e-05, 'mean_token_accuracy': 0.65673828125, 'epoch': 0.02}\r\n",
      "{'loss': 1.4393, 'grad_norm': 1.4274466037750244, 'learning_rate': 1.3535353535353538e-05, 'mean_token_accuracy': 0.6578369140625, 'epoch': 0.03}\r\n",
      "{'loss': 1.3375, 'grad_norm': 1.4621531963348389, 'learning_rate': 1.3333333333333333e-05, 'mean_token_accuracy': 0.651123046875, 'epoch': 0.03}\r\n",
      "{'loss': 1.4629, 'grad_norm': 1.4180935621261597, 'learning_rate': 1.3131313131313132e-05, 'mean_token_accuracy': 0.615478515625, 'epoch': 0.03}\r\n",
      "{'loss': 1.5449, 'grad_norm': 1.2644431591033936, 'learning_rate': 1.2929292929292931e-05, 'mean_token_accuracy': 0.6015625, 'epoch': 0.03}\r\n",
      "{'loss': 1.7157, 'grad_norm': 1.3876068592071533, 'learning_rate': 1.2727272727272728e-05, 'mean_token_accuracy': 0.6029052734375, 'epoch': 0.03}\r\n",
      "{'loss': 1.4943, 'grad_norm': 1.3739982843399048, 'learning_rate': 1.2525252525252527e-05, 'mean_token_accuracy': 0.646484375, 'epoch': 0.03}\r\n",
      "{'loss': 1.3525, 'grad_norm': 1.45365571975708, 'learning_rate': 1.2323232323232323e-05, 'mean_token_accuracy': 0.6436767578125, 'epoch': 0.03}\r\n",
      "{'loss': 1.3505, 'grad_norm': 1.6654123067855835, 'learning_rate': 1.2121212121212122e-05, 'mean_token_accuracy': 0.62646484375, 'epoch': 0.03}\r\n",
      "{'loss': 1.153, 'grad_norm': 1.4946832656860352, 'learning_rate': 1.191919191919192e-05, 'mean_token_accuracy': 0.677734375, 'epoch': 0.03}\r\n",
      "{'loss': 1.2479, 'grad_norm': 1.4359008073806763, 'learning_rate': 1.1717171717171718e-05, 'mean_token_accuracy': 0.6783447265625, 'epoch': 0.03}\r\n",
      "{'loss': 1.4834, 'grad_norm': 1.5005764961242676, 'learning_rate': 1.1515151515151517e-05, 'mean_token_accuracy': 0.6063232421875, 'epoch': 0.03}\r\n",
      "{'loss': 1.1931, 'grad_norm': 1.558270812034607, 'learning_rate': 1.1313131313131314e-05, 'mean_token_accuracy': 0.665771484375, 'epoch': 0.03}\r\n",
      "{'loss': 1.4271, 'grad_norm': 1.7744585275650024, 'learning_rate': 1.1111111111111113e-05, 'mean_token_accuracy': 0.630615234375, 'epoch': 0.03}\r\n",
      "{'loss': 1.4541, 'grad_norm': 1.5425159931182861, 'learning_rate': 1.0909090909090909e-05, 'mean_token_accuracy': 0.608154296875, 'epoch': 0.03}\r\n",
      "{'loss': 1.1595, 'grad_norm': 1.6690821647644043, 'learning_rate': 1.0707070707070708e-05, 'mean_token_accuracy': 0.673583984375, 'epoch': 0.04}\r\n",
      "{'loss': 1.6748, 'grad_norm': 1.6003440618515015, 'learning_rate': 1.0505050505050507e-05, 'mean_token_accuracy': 0.613037109375, 'epoch': 0.04}\r\n",
      "{'loss': 1.916, 'grad_norm': 2.009650945663452, 'learning_rate': 1.0303030303030304e-05, 'mean_token_accuracy': 0.568115234375, 'epoch': 0.04}\r\n",
      "{'loss': 1.457, 'grad_norm': 1.6769089698791504, 'learning_rate': 1.0101010101010103e-05, 'mean_token_accuracy': 0.6383056640625, 'epoch': 0.04}\r\n",
      "{'loss': 1.8439, 'grad_norm': 1.8775488138198853, 'learning_rate': 9.8989898989899e-06, 'mean_token_accuracy': 0.57568359375, 'epoch': 0.04}\r\n",
      "{'loss': 1.4404, 'grad_norm': 1.6035008430480957, 'learning_rate': 9.696969696969698e-06, 'mean_token_accuracy': 0.6279296875, 'epoch': 0.04}\r\n",
      "{'loss': 1.2299, 'grad_norm': 1.7814749479293823, 'learning_rate': 9.494949494949497e-06, 'mean_token_accuracy': 0.64453125, 'epoch': 0.04}\r\n",
      "{'loss': 1.2764, 'grad_norm': 1.7814003229141235, 'learning_rate': 9.292929292929294e-06, 'mean_token_accuracy': 0.6429443359375, 'epoch': 0.04}\r\n",
      "{'loss': 1.3641, 'grad_norm': 1.7192156314849854, 'learning_rate': 9.090909090909091e-06, 'mean_token_accuracy': 0.6502685546875, 'epoch': 0.04}\r\n",
      "{'loss': 1.2199, 'grad_norm': 1.8035756349563599, 'learning_rate': 8.888888888888888e-06, 'mean_token_accuracy': 0.68701171875, 'epoch': 0.04}\r\n",
      "{'loss': 1.3697, 'grad_norm': 1.8828619718551636, 'learning_rate': 8.686868686868687e-06, 'mean_token_accuracy': 0.6605224609375, 'epoch': 0.04}\r\n",
      "{'loss': 1.6002, 'grad_norm': 1.6703925132751465, 'learning_rate': 8.484848484848486e-06, 'mean_token_accuracy': 0.60089111328125, 'epoch': 0.04}\r\n",
      "{'loss': 1.065, 'grad_norm': 1.4990787506103516, 'learning_rate': 8.282828282828283e-06, 'mean_token_accuracy': 0.6839599609375, 'epoch': 0.04}\r\n",
      "{'loss': 1.442, 'grad_norm': 1.6479759216308594, 'learning_rate': 8.08080808080808e-06, 'mean_token_accuracy': 0.6373291015625, 'epoch': 0.05}\r\n",
      "{'loss': 1.3314, 'grad_norm': 1.5769377946853638, 'learning_rate': 7.87878787878788e-06, 'mean_token_accuracy': 0.6395263671875, 'epoch': 0.05}\r\n",
      "{'loss': 1.1222, 'grad_norm': 1.5380562543869019, 'learning_rate': 7.676767676767677e-06, 'mean_token_accuracy': 0.66650390625, 'epoch': 0.05}\r\n",
      "{'loss': 1.5898, 'grad_norm': 1.4711538553237915, 'learning_rate': 7.474747474747476e-06, 'mean_token_accuracy': 0.6220703125, 'epoch': 0.05}\r\n",
      "{'loss': 1.271, 'grad_norm': 1.3432855606079102, 'learning_rate': 7.272727272727273e-06, 'mean_token_accuracy': 0.658203125, 'epoch': 0.05}\r\n",
      "{'loss': 1.3796, 'grad_norm': 1.5002151727676392, 'learning_rate': 7.070707070707071e-06, 'mean_token_accuracy': 0.6639404296875, 'epoch': 0.05}\r\n",
      "{'loss': 1.2328, 'grad_norm': 1.237181544303894, 'learning_rate': 6.868686868686869e-06, 'mean_token_accuracy': 0.666015625, 'epoch': 0.05}\r\n",
      "{'loss': 1.4428, 'grad_norm': 1.2964394092559814, 'learning_rate': 6.666666666666667e-06, 'mean_token_accuracy': 0.6629638671875, 'epoch': 0.05}\r\n",
      "{'loss': 1.4453, 'grad_norm': 1.5260813236236572, 'learning_rate': 6.464646464646466e-06, 'mean_token_accuracy': 0.6627197265625, 'epoch': 0.05}\r\n",
      "{'loss': 1.6921, 'grad_norm': 1.3892929553985596, 'learning_rate': 6.262626262626264e-06, 'mean_token_accuracy': 0.63134765625, 'epoch': 0.05}\r\n",
      "{'loss': 1.2881, 'grad_norm': 1.3491086959838867, 'learning_rate': 6.060606060606061e-06, 'mean_token_accuracy': 0.6754150390625, 'epoch': 0.05}\r\n",
      "{'loss': 1.3322, 'grad_norm': 1.1107319593429565, 'learning_rate': 5.858585858585859e-06, 'mean_token_accuracy': 0.6641845703125, 'epoch': 0.05}\r\n",
      "{'loss': 1.3207, 'grad_norm': 1.1329313516616821, 'learning_rate': 5.656565656565657e-06, 'mean_token_accuracy': 0.6676025390625, 'epoch': 0.05}\r\n",
      "{'loss': 1.2737, 'grad_norm': 1.2457129955291748, 'learning_rate': 5.4545454545454545e-06, 'mean_token_accuracy': 0.6700439453125, 'epoch': 0.06}\r\n",
      "{'loss': 1.2679, 'grad_norm': 1.4359002113342285, 'learning_rate': 5.252525252525253e-06, 'mean_token_accuracy': 0.6484375, 'epoch': 0.06}\r\n",
      "{'loss': 1.5376, 'grad_norm': 1.2810286283493042, 'learning_rate': 5.0505050505050515e-06, 'mean_token_accuracy': 0.6256103515625, 'epoch': 0.06}\r\n",
      "{'loss': 1.3746, 'grad_norm': 1.4105640649795532, 'learning_rate': 4.848484848484849e-06, 'mean_token_accuracy': 0.6268310546875, 'epoch': 0.06}\r\n",
      "{'loss': 1.3881, 'grad_norm': 1.1888338327407837, 'learning_rate': 4.646464646464647e-06, 'mean_token_accuracy': 0.6473388671875, 'epoch': 0.06}\r\n",
      "{'loss': 1.4007, 'grad_norm': 1.231087327003479, 'learning_rate': 4.444444444444444e-06, 'mean_token_accuracy': 0.6397705078125, 'epoch': 0.06}\r\n",
      "{'loss': 1.2315, 'grad_norm': 1.2201402187347412, 'learning_rate': 4.242424242424243e-06, 'mean_token_accuracy': 0.653564453125, 'epoch': 0.06}\r\n",
      "{'loss': 1.2857, 'grad_norm': 1.4165302515029907, 'learning_rate': 4.04040404040404e-06, 'mean_token_accuracy': 0.679931640625, 'epoch': 0.06}\r\n",
      "{'loss': 1.565, 'grad_norm': 1.1762614250183105, 'learning_rate': 3.8383838383838385e-06, 'mean_token_accuracy': 0.639892578125, 'epoch': 0.06}\r\n",
      "{'loss': 1.1193, 'grad_norm': 1.6215113401412964, 'learning_rate': 3.6363636363636366e-06, 'mean_token_accuracy': 0.6820068359375, 'epoch': 0.06}\r\n",
      "{'loss': 1.607, 'grad_norm': 1.2934601306915283, 'learning_rate': 3.4343434343434347e-06, 'mean_token_accuracy': 0.61279296875, 'epoch': 0.06}\r\n",
      "{'loss': 1.2621, 'grad_norm': 1.4108922481536865, 'learning_rate': 3.232323232323233e-06, 'mean_token_accuracy': 0.64013671875, 'epoch': 0.06}\r\n",
      "{'loss': 1.4965, 'grad_norm': 1.2565921545028687, 'learning_rate': 3.0303030303030305e-06, 'mean_token_accuracy': 0.6307373046875, 'epoch': 0.06}\r\n",
      "{'loss': 1.2944, 'grad_norm': 1.209383249282837, 'learning_rate': 2.8282828282828286e-06, 'mean_token_accuracy': 0.650634765625, 'epoch': 0.07}\r\n",
      "{'loss': 1.6392, 'grad_norm': 1.5751488208770752, 'learning_rate': 2.6262626262626267e-06, 'mean_token_accuracy': 0.615966796875, 'epoch': 0.07}\r\n",
      "{'loss': 1.2917, 'grad_norm': 1.1408816576004028, 'learning_rate': 2.4242424242424244e-06, 'mean_token_accuracy': 0.6624755859375, 'epoch': 0.07}\r\n",
      "{'loss': 1.2649, 'grad_norm': 1.459474802017212, 'learning_rate': 2.222222222222222e-06, 'mean_token_accuracy': 0.6807861328125, 'epoch': 0.07}\r\n",
      "{'loss': 1.1471, 'grad_norm': 1.2571465969085693, 'learning_rate': 2.02020202020202e-06, 'mean_token_accuracy': 0.6822509765625, 'epoch': 0.07}\r\n",
      "{'loss': 1.5047, 'grad_norm': 1.492645502090454, 'learning_rate': 1.8181818181818183e-06, 'mean_token_accuracy': 0.6441650390625, 'epoch': 0.07}\r\n",
      "{'loss': 1.4094, 'grad_norm': 1.1614223718643188, 'learning_rate': 1.6161616161616164e-06, 'mean_token_accuracy': 0.6385498046875, 'epoch': 0.07}\r\n",
      "{'loss': 1.4489, 'grad_norm': 1.3489580154418945, 'learning_rate': 1.4141414141414143e-06, 'mean_token_accuracy': 0.637939453125, 'epoch': 0.07}\r\n",
      "{'loss': 1.2015, 'grad_norm': 1.4533171653747559, 'learning_rate': 1.2121212121212122e-06, 'mean_token_accuracy': 0.6712646484375, 'epoch': 0.07}\r\n",
      "{'loss': 1.3427, 'grad_norm': 1.2427995204925537, 'learning_rate': 1.01010101010101e-06, 'mean_token_accuracy': 0.6593017578125, 'epoch': 0.07}\r\n",
      "{'loss': 1.5544, 'grad_norm': 1.2351244688034058, 'learning_rate': 8.080808080808082e-07, 'mean_token_accuracy': 0.6373291015625, 'epoch': 0.07}\r\n",
      "{'loss': 1.496, 'grad_norm': 1.2558321952819824, 'learning_rate': 6.060606060606061e-07, 'mean_token_accuracy': 0.6234130859375, 'epoch': 0.07}\r\n",
      "{'loss': 1.0187, 'grad_norm': 1.2020610570907593, 'learning_rate': 4.040404040404041e-07, 'mean_token_accuracy': 0.694580078125, 'epoch': 0.07}\r\n",
      "{'loss': 1.3996, 'grad_norm': 1.591642141342163, 'learning_rate': 2.0202020202020205e-07, 'mean_token_accuracy': 0.6480712890625, 'epoch': 0.08}\r\n",
      "{'loss': 1.3019, 'grad_norm': 1.1963422298431396, 'learning_rate': 0.0, 'mean_token_accuracy': 0.6663818359375, 'epoch': 0.08}\r\n",
      "{'train_runtime': 1508.7987, 'train_samples_per_second': 1.06, 'train_steps_per_second': 0.066, 'train_loss': 1.4713134312629699, 'epoch': 0.08}\r\n",
      "100%|█████████████████████████████████████████| 100/100 [25:08<00:00, 15.09s/it]\r\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch --config_file \"/kaggle/working/config.yaml\"  /kaggle/working/unsloth.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117bda7",
   "metadata": {
    "papermill": {
     "duration": 0.03555,
     "end_time": "2025-03-05T15:32:33.281308",
     "exception": false,
     "start_time": "2025-03-05T15:32:33.245758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1799.882554,
   "end_time": "2025-03-05T15:32:34.143795",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-05T15:02:34.261241",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
